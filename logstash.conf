input {
	file {
		# the path to the logfile in question. need to change to reproduct
		path => "/Users/angus/Desktop/access.log"

		#these params ensure the logfile is parsed from the begining each time logstash is run
		start_position => 'beginning' 
		sincedb_path => '/dev/null'
	}	
}

filter {

		# grok patterns are basically high level regex - note need to work on this one and/or create others for edge cases
		grok {
			match => ["message", '%{IPORHOST:clientip} - %{USER:ident}?-%{USER:auth}? \[%{HTTPDATE:request_timestamp}\] "(?:%{WORD:verb} %{URIPATHPARAM:request}(?: HTTP/%{NUMBER:httpversion})?|-)" %{NUMBER:response} %{NUMBER:bytes} %{NUMBER:microseconds}']
			match => ["message", '%{IPORHOST:clientip} - %{USER:ident}?-%{USER:auth}? \[%{HTTPDATE:request_timestamp}\] \\\"%{WORD:word} \* HTTP/%{NUMBER:httpversion}\\\" %{NUMBER:response} - %{NUMBER:microseconds}']

		}

		#changes the @timestamp to be that of the log message
		date {
			match => [ "request_timestamp", "dd/MMM/YYYY:HH:mm:ss Z" ]
		}
}

output {
	if "_grokparsefailure" in [tags] {
		#this was done to prevent grokfailures from messing up the stats. given more time I would find create groks for all pattern types
		 elasticsearch {
            host => localhost
            protocol => "http"
            cluster  =>  "elasticsearch_angus"
            index => "apache_logs_grok_failures"
            port => "9200"
        }
	} else {
		# send all logs to elasticsearch cluster running on localhost
		elasticsearch { 
			host => localhost
			protocol => "http"
			cluster  =>  "elasticsearch_angus"
			index => "apache_logs"
			port => "9200"
		}
	}

#	below block can be uncommented to aid in grok debugging.
#	file {
#		path => "/Users/angus/workspace/loquacious-octo-kumquat/stdout.log"
#	}

#	stdout {
#            codec => "rubydebug"
#    }
}

